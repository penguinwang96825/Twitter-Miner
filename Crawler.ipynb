{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search API\n",
    "def crawl_tweet_dataframe(hashtag, count): \n",
    "    \"\"\"\n",
    "    Get KEY and ACCESS TOKEN from https://developer.twitter.com/en/apps\n",
    "    \n",
    "    Parameters:\n",
    "        hashtag: the search query string of 500 characters maximum, including operators.\n",
    "        count: the number of results to try and retrieve per page.\n",
    "    \"\"\"\n",
    "    authentication = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    authentication.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "    api = tweepy.API(authentication, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    maxId = -1\n",
    "    tweetCount = 0\n",
    "\n",
    "    tweet_list = []\n",
    "    while tweetCount < maxTweets: \n",
    "        if(maxId <= 0):\n",
    "            newTweets = api.search(\n",
    "                q=hashtag, count=tweetsPerQry, result_type=\"recent\", tweet_mode=\"extended\")\n",
    "        else:\n",
    "            newTweets = api.search(\n",
    "                q=hashtag, count=tweetsPerQry, max_id=str(maxId - 1), result_type=\"recent\", tweet_mode=\"extended\")\n",
    "\n",
    "        if not newTweets:\n",
    "            print(\"Tweet Habis\")\n",
    "            break\n",
    "\n",
    "        for tweet in newTweets:\n",
    "            user = tweet.user.screen_name.encode('utf-8')\n",
    "            content = tweet.full_text.encode('utf-8')\n",
    "            date = tweet.created_at\n",
    "            likes = tweet.favorite_count\n",
    "            location = tweet.coordinates[\"coordinates\"] if tweet.coordinates is not None else None\n",
    "            tweet_list.append([user, content, date, likes, location])\n",
    "\n",
    "        tweetCount += len(newTweets)\n",
    "        maxId = newTweets[-1].id\n",
    "\n",
    "    tweet_df = pd.DataFrame(tweet_list)\n",
    "    tweet_df.columns = [\"user\", \"text\", \"date\", \"likes\", \"location\"]\n",
    "    tweet_df[\"user\"] = tweet_df[\"user\"].apply(lambda x: x.decode(\"utf-8\"))\n",
    "    tweet_df[\"text\"] = tweet_df[\"text\"].apply(lambda x: x.decode(\"utf-8\"))\n",
    "\n",
    "    return tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  tweet_length  \\\n",
      "0  @abhi1thakur Are dolphins good at deploying mo...            51   \n",
      "1  torchvision has a lot of tools for CV but not ...           122   \n",
      "2  Question: What is the @huggingface of computer...            56   \n",
      "3  @AnjumSayed @Shahules786 Yes, no need to see t...            95   \n",
      "4  And some other top solutions here: https://t.c...            58   \n",
      "5          And now https://t.co/ZxL7vcbjiC is 12th.ðŸ˜Ž            41   \n",
      "6  First place from the DeepFake challenge has be...           135   \n",
      "7  @Shahules786 You should at least cover the fro...            88   \n",
      "8                  @lexfridman What is the source? ðŸ‘€            33   \n",
      "9  It seems people want more quota. What is a \"fa...            69   \n",
      "\n",
      "                    id geography  favorite_count  retweet_count  \\\n",
      "0  1271854926357049345      None               1              0   \n",
      "1  1271840119973187590      None               2              0   \n",
      "2  1271839791349366785      None              26              5   \n",
      "3  1271693723894767617      None               2              0   \n",
      "4  1271518603934867462      None               0              0   \n",
      "5  1271515140870078471      None               1              0   \n",
      "6  1271514735381544961      None               3              0   \n",
      "7  1271491716428726275      None               3              0   \n",
      "8  1271213515030888454      None               0              0   \n",
      "9  1271199029209292801      None               0              0   \n",
      "\n",
      "                 date           source  \n",
      "0 2020-06-13 17:20:19  Twitter Web App  \n",
      "1 2020-06-13 16:21:28  Twitter Web App  \n",
      "2 2020-06-13 16:20:10  Twitter Web App  \n",
      "3 2020-06-13 06:39:45  Twitter Web App  \n",
      "4 2020-06-12 19:03:53  Twitter Web App  \n",
      "5 2020-06-12 18:50:07  Twitter Web App  \n",
      "6 2020-06-12 18:48:31  Twitter Web App  \n",
      "7 2020-06-12 17:17:03  Twitter Web App  \n",
      "8 2020-06-11 22:51:34  Twitter Web App  \n",
      "9 2020-06-11 21:54:00  Twitter Web App  \n"
     ]
    }
   ],
   "source": [
    "# Streaming API\n",
    "class TwitterAuth():\n",
    "    \"\"\"\n",
    "    Get authentication for Twitter.\n",
    "    from config import CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET\n",
    "    \"\"\"\n",
    "    def auth_twitter_app(self):\n",
    "        auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "        auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "        return auth\n",
    "\n",
    "class MaxListener(tweepy.StreamListener):\n",
    "    \"\"\"\n",
    "    This simple stream listener prints status text.\n",
    "    \"\"\"\n",
    "    def __init__(self, tweets_filename):\n",
    "        self.tweets_filename = tweets_filename\n",
    "    \n",
    "    def on_data(self, raw_data):\n",
    "        self.process_data(raw_data)\n",
    "        return True\n",
    "    \n",
    "    def process_data(self, raw_data):\n",
    "        try:\n",
    "            print(raw_data)\n",
    "            with open(self.tweets_filename, 'a') as f:\n",
    "                f.write(raw_data)\n",
    "            return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error on data: {}\".format(e))\n",
    "        return True \n",
    "        \n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            return False\n",
    "        \n",
    "class MaxStreamer():\n",
    "    \"\"\"\n",
    "    In Tweepy, an instance of tweepy.Stream establishes a streaming session and routes messages to StreamListener instance.\n",
    "    \n",
    "    Parameters:\n",
    "        tweets_filename: json file name.\n",
    "    \"\"\"\n",
    "    def __init__(self, tweets_filename):\n",
    "        self.auth = TwitterAuth().auth_twitter_app()\n",
    "        self.listener = MaxListener(tweets_filename=tweets_filename)\n",
    "        self.stream = tweepy.Stream(auth=self.auth, listener=self.listener)\n",
    "        \n",
    "    def start(self, keyword):\n",
    "        keyword_list = [keyword]\n",
    "        self.stream.filter(track=keyword_list)\n",
    "        \n",
    "class TwitterClient():\n",
    "    \"\"\"\n",
    "    Get my own tweets or others.\n",
    "    \n",
    "    Parameters:\n",
    "        twitter_user: if twitter_user is set to None, it means capture my tweets. Instead, crawl twitter_user tweets. \n",
    "    \"\"\"\n",
    "    def __init__(self, twitter_user=None):\n",
    "        self.auth = TwitterAuth().auth_twitter_app()\n",
    "        self.twitter_client = tweepy.API(self.auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "        self.twitter_user = twitter_user\n",
    "        \n",
    "    def get_twitter_client_api(self):\n",
    "        return self.twitter_client\n",
    "        \n",
    "    def get_user_timeline_tweets(self, num_tweets):\n",
    "        tweets = []\n",
    "        for tweet in tweepy.Cursor(self.twitter_client.user_timeline, id=self.twitter_user).items(num_tweets):\n",
    "            tweets.append(tweet)\n",
    "        return tweets\n",
    "    \n",
    "    def get_friend_list(self, num_friends):\n",
    "        friend_list = []\n",
    "        for friend in tweepy.Cursor(self.twitter_client.friends, id=self.twitter_user).items(num_friends):\n",
    "            friend_list.append(friend)\n",
    "        return friend_list\n",
    "    \n",
    "    def get_home_timeline_tweets(self, num_tweets):\n",
    "        home_timeline_tweets = []\n",
    "        for tweet in tweepy.Cursor(self.twitter_client.home_timeline, id=self.twitter_user).items(num_tweets):\n",
    "            home_timeline_tweets.append(tweet)\n",
    "        return home_timeline_tweets\n",
    "    \n",
    "class TweetAnalyzer():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def tweets_to_dataframe(self, tweets):\n",
    "        df = pd.DataFrame()\n",
    "        df[\"tweet\"] = np.array([tweet.text for tweet in tweets])\n",
    "        df[\"tweet_length\"] = np.array([len(tweet.text) for tweet in tweets])\n",
    "        df[\"id\"] = np.array([tweet.id for tweet in tweets])\n",
    "        df[\"geography\"] = np.array([tweet.geo for tweet in tweets])\n",
    "        df[\"favorite_count\"] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "        df[\"retweet_count\"] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "        df[\"date\"] = np.array([tweet.created_at for tweet in tweets])\n",
    "        df[\"source\"] = np.array([tweet.source for tweet in tweets])\n",
    "        return df\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "#     stream = MaxStreamer(tweets_filename=\"tweets.json\")\n",
    "#     stream.start(\"python\")\n",
    "#     twitter_client = TwitterClient(twitter_user=\"YassineAlouini\")\n",
    "#     print(twitter_client.get_friend_list(1))\n",
    "    tweet_analyzer = TweetAnalyzer()\n",
    "    api = TwitterClient().get_twitter_client_api()\n",
    "    tweets = api.user_timeline(screen_name=\"YassineAlouini\", count=10)\n",
    "    df = tweet_analyzer.tweets_to_dataframe(tweets)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 698\n",
      "Rate limit reached. Sleeping for: 707\n"
     ]
    }
   ],
   "source": [
    "tweetsPerQry = 100\n",
    "maxTweets = 100000\n",
    "hashtag = \"#trump\"\n",
    "\n",
    "tweet_df = crawl_tweet_dataframe(\n",
    "    hashtag=hashtag, \n",
    "    count=tweetsPerQry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of tweets: {}\".format(len(tweet_df)))\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "sns.heatmap(tweet_df.isnull(), cbar=True, cmap=sns.color_palette(\"GnBu_d\"))\n",
    "plt.title(\"Missing Values Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
